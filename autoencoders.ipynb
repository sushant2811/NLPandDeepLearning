{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various working examples of autoencoders\n",
    "\n",
    "Ref: [Keras blog](https://blog.keras.io/building-autoencoders-in-keras.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sushantmore/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#the size of the encoded representation\n",
    "encodingDim = 32 # 32 floats -> compression of factor 24.5, assuming the input is 784 floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# placeholder for the input image\n",
    "inputImg = Input(shape=(784,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"encoded\" is the encoded representation of the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoded = Dense(encodingDim, activation='relu')(inputImg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decoded = Dense(784, activation='sigmoid')(encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try another network with the relu activation function in the decoder and check the performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(inputImg, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25120"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "785 * 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "33 * 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the same network using the Sequential class of keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoderSeq = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoderSeq.add(Dense(encodingDim, input_shape=(784,), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoderSeq.add(Dense(784, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 32)                25120     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 784)               25872     \n",
      "=================================================================\n",
      "Total params: 50,992\n",
      "Trainable params: 50,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoderSeq.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.models.Sequential"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(autoencoderSeq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's train the network to reconstruct MNIST digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoderSeq.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(Xtrain, ytrain), (Xtest, ytest) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtrainScaled = Xtrain.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtestScaled = Xtest.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can think of the above as MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(XtrainScaled.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtrainScaledFlatten = XtrainScaled.reshape((len(XtrainScaled), np.prod(XtrainScaled.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XtestScaledFlatten = XtestScaled.reshape((len(XtestScaled), np.prod(XtestScaled.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XtrainScaledFlatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0940 - val_loss: 0.0927\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0940 - val_loss: 0.0926\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 3s 45us/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0939 - val_loss: 0.0925\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.093 - 2s 31us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0938 - val_loss: 0.0925\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0937 - val_loss: 0.0925\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 38/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0937 - val_loss: 0.0924\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0936 - val_loss: 0.0924\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0936 - val_loss: 0.0924\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0935 - val_loss: 0.0923\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0934 - val_loss: 0.0922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0934 - val_loss: 0.0921\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 3s 44us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 100/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 3s 43us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 2s 36us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0932 - val_loss: 0.0919\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 2s 37us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 162/200\n",
      "60000/60000 [==============================] - 2s 41us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 3s 42us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 2s 39us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 2s 28us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 2s 30us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 2s 31us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 2s 35us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 2s 34us/step - loss: 0.0931 - val_loss: 0.0918\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 2s 33us/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 2s 32us/step - loss: 0.0930 - val_loss: 0.0918\n"
     ]
    }
   ],
   "source": [
    "history = autoencoder.fit(XtrainScaledFlatten, XtrainScaledFlatten, epochs=200, \n",
    "                          batch_size=256, shuffle=True, verbose=1, validation_data=(XtestScaledFlatten, XtestScaledFlatten)).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAEKCAYAAAAvlUMdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10de2ca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss']);\n",
    "plt.plot(history['val_loss']);\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set loss', 'validation set loss']);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
